import pandas as pd
import os
import re
from rich.panel import Panel
from rich.console import Console
import autocorrect_py as autocorrect
from core.utils import *
from core.utils.models import *
from difflib import SequenceMatcher

console = Console()

SUBTITLE_OUTPUT_CONFIGS = [ 
    ('src.srt', ['Source']),
    ('trans.srt', ['Translation']),
    ('src_trans.srt', ['Source', 'Translation']),
    ('trans_src.srt', ['Translation', 'Source'])
]

AUDIO_SUBTITLE_OUTPUT_CONFIGS = [
    ('src_subs_for_audio.srt', ['Source']),
    ('trans_subs_for_audio.srt', ['Translation'])
]

def convert_to_srt_format(start_time, end_time):
    """Convert time (in seconds) to the format: hours:minutes:seconds,milliseconds"""
    def seconds_to_hmsm(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int(seconds * 1000) % 1000
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"

    start_srt = seconds_to_hmsm(start_time)
    end_srt = seconds_to_hmsm(end_time)
    return f"{start_srt} --> {end_srt}"

def remove_punctuation(text):
    # å¼ºåŒ–æ¸…æ´—é€»è¾‘ï¼Œç»Ÿä¸€å¤„ç†ä¸ºå­—ç¬¦ä¸²ï¼Œç§»é™¤æ ‡ç‚¹
    text = re.sub(r'\s+', ' ', str(text))
    text = re.sub(r'[^\w\s]', '', text)
    return text.strip()

def find_best_match(query, text, start_pos, search_window=2500, threshold=0.6):
    """åœ¨æŒ‡å®šçª—å£å†…å¯»æ‰¾æœ€ä½³æ¨¡ç³ŠåŒ¹é…"""
    search_limit = min(len(text), start_pos + search_window)
    window_text = text[start_pos:search_limit]
    
    if not query or not window_text:
        return None

    # 1. å°è¯•ç›´æ¥åŒ¹é…ï¼ˆæœ€é«˜æ•ˆï¼‰
    exact_idx = window_text.find(query)
    if exact_idx != -1:
        return (start_pos + exact_idx, start_pos + exact_idx + len(query))

    # 2. æ¨¡ç³ŠåŒ¹é…
    matcher = SequenceMatcher(None, query, window_text)
    match = matcher.find_longest_match(0, len(query), 0, len(window_text))
    
    # åªæœ‰å½“åŒ¹é…é•¿åº¦å åŸå¥ä¸€å®šæ¯”ä¾‹æ—¶æ‰è®¤ä¸ºæœ‰æ•ˆ
    if match.size / len(query) > threshold:
        abs_start = start_pos + match.b
        abs_end = abs_start + match.size
        return (abs_start, abs_end)
    
    return None

def get_sentence_timestamps(df_words, df_sentences):
    time_stamp_list = []
    
    # æ„å»ºå…¨æ–‡å­—ç¬¦ä¸²å’Œä½ç½®ç´¢å¼•æ˜ å°„
    full_words_str = ''
    position_to_word_idx = {}
    
    for idx, word in enumerate(df_words['text']):
        clean_word = remove_punctuation(word.lower())
        start_pos = len(full_words_str)
        full_words_str += clean_word
        for pos in range(start_pos, len(full_words_str)):
            position_to_word_idx[pos] = idx
            
    current_pos = 0
    last_end_time = 0.0
    
    sentences = df_sentences['Source'].tolist()
    total_sentences = len(sentences)
    i = 0
    
    while i < total_sentences:
        sentence = sentences[i]
        clean_sentence = remove_punctuation(sentence.lower()).replace(" ", "")
        
        # å¦‚æœå¥å­ä¸ºç©ºï¼Œç›´æ¥ç»™ä¸€ä¸ªæçŸ­çš„æ—¶é—´
        if not clean_sentence:
            time_stamp_list.append((last_end_time, last_end_time + 0.1))
            last_end_time += 0.1
            i += 1
            continue

        # === ç­–ç•¥1: å°è¯•å½“å‰å¥å­çš„åŒ¹é… ===
        match_span = find_best_match(clean_sentence, full_words_str, current_pos)
        
        if match_span:
            # æ‰¾åˆ°åŒ¹é…ï¼Œæå–æ—¶é—´
            start_idx = match_span[0]
            end_idx = match_span[1] - 1 # inclusive
            
            # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç´¢å¼•è¶Šç•Œ
            if start_idx in position_to_word_idx and end_idx in position_to_word_idx:
                start_word_idx = position_to_word_idx[start_idx]
                end_word_idx = position_to_word_idx[end_idx]
                
                start_t = float(df_words['start'][start_word_idx])
                end_t = float(df_words['end'][end_word_idx])
                
                # ä¿®æ­£ï¼šå¼€å§‹æ—¶é—´ä¸èƒ½æ—©äºä¸Šä¸€å¥ç»“æŸæ—¶é—´
                if start_t < last_end_time:
                    start_t = last_end_time
                if end_t < start_t:
                    end_t = start_t + 0.1

                time_stamp_list.append((start_t, end_t))
                last_end_time = end_t
                current_pos = match_span[1]
                i += 1
                continue

        # === ç­–ç•¥2: åŒ¹é…å¤±è´¥ï¼Œå¯ç”¨å‰ç» (Smart Lookahead) ===
        # æ—¢ç„¶å½“å‰å¥å­æ‰¾ä¸åˆ°ï¼Œæˆ‘ä»¬çœ‹çœ‹ä¸‹ä¸€å¥èƒ½ä¸èƒ½æ‰¾åˆ°
        console.print(f"[yellow]âš ï¸ Match failed for: '{sentence[:20]}...', looking ahead...[/yellow]")
        
        next_match_span = None
        lookahead_idx = i + 1
        
        # å‘åçœ‹1å¥ï¼ˆå¦‚æœéœ€è¦æ›´å¼ºé²æ£’æ€§å¯ä»¥å¾ªç¯å‘åçœ‹ï¼Œä½†1å¥é€šå¸¸è¶³å¤Ÿï¼‰
        if lookahead_idx < total_sentences:
            next_sent = sentences[lookahead_idx]
            clean_next = remove_punctuation(next_sent.lower()).replace(" ", "")
            if clean_next:
                # åœ¨æ›´è¿œçš„çª—å£å¯»æ‰¾ä¸‹ä¸€å¥
                next_match_span = find_best_match(clean_next, full_words_str, current_pos, search_window=3000)
        
        if next_match_span:
            # === ç­–ç•¥2.1: ä¸‹ä¸€å¥æ‰¾åˆ°äº† ===
            # ä¸‹ä¸€å¥çš„å¼€å§‹ä½ç½®
            next_start_idx = next_match_span[0]
            if next_start_idx in position_to_word_idx:
                next_start_t = float(df_words['start'][position_to_word_idx[next_start_idx]])
            else:
                next_start_t = last_end_time + 2.0
            
            # å½“å‰ä¸¢å¤±çš„å¥å­ï¼Œå°±å¡«è¡¥åœ¨ [last_end_time, next_start_t] ä¹‹é—´
            # è‡³å°‘ä¿ç•™0.5ç§’ç»™å®ƒï¼Œé¿å…æ—¶é—´å€’æµ
            if next_start_t <= last_end_time:
                next_start_t = last_end_time + 1.0
                
            console.print(f"[green]âœ… Recovered using lookahead. Assigning interval {last_end_time:.2f}-{next_start_t:.2f}[/green]")
            time_stamp_list.append((last_end_time, next_start_t))
            last_end_time = next_start_t
            
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸ç§»åŠ¨ current_posï¼Œä¹Ÿä¸å¢åŠ  i
            # å› ä¸ºä¸‹ä¸€è½®å¾ªç¯å¤„ç† i+1 æ—¶ï¼Œä¼šå†æ¬¡æ‰¾åˆ°è¿™ä¸ª next_match_span å¹¶æ­£å¸¸å¤„ç†
            # è¿™é‡Œçš„ç›®çš„æ˜¯ç»™å½“å‰â€œä¸¢å¤±â€çš„å¥å­ i åˆ†é…æ—¶é—´
            
            # ä¿®æ­£ï¼šä¸ºäº†é¿å…ä¸‹ä¸€è½®é‡å¤æœç´¢å¸¦æ¥çš„å¼€é”€ï¼Œå…¶å®å¯ä»¥ç›´æ¥åœ¨è¿™é‡Œè·³è¿‡å—ï¼Ÿ
            # ä¸ï¼Œä¿æŒ current_pos ä¸å˜ï¼Œä¸‹ä¸€è½® i+1 è‡ªç„¶ä¼šåŒ¹é…åˆ° next_match_spanï¼Œé€»è¾‘æ›´ç®€å•
            i += 1
            
        else:
            # === ç­–ç•¥3: å½»åº•å¤±è´¥ (å½“å‰å’Œä¸‹ä¸€å¥éƒ½æ‰¾ä¸åˆ°) ===
            # åªèƒ½æ ¹æ®æ–‡æœ¬é•¿åº¦ä¼°ç®—ä¸€ä¸ªæ—¶é—´äº†
            estimated_duration = len(sentence) * 0.1 + 0.5 # æ¯ä¸ªå­—0.1ç§’ + 0.5ç§’åŸºç¡€
            if estimated_duration > 5.0: estimated_duration = 5.0
            
            console.print(f"[red]âŒ Completely lost match for: '{sentence[:15]}...'. Estimating {estimated_duration:.1f}s[/red]")
            
            start_t = last_end_time
            end_t = last_end_time + estimated_duration
            time_stamp_list.append((start_t, end_t))
            last_end_time = end_t
            # è¿™ç§æƒ…å†µä¸‹ä¸ç§»åŠ¨ current_posï¼Œå¸Œæœ›åé¢èƒ½é‡æ–°å¯¹é½
            i += 1

    return time_stamp_list

def align_timestamp(df_text, df_translate, subtitle_output_configs: list, output_dir: str, for_display: bool = True):
    """Align timestamps and add a new timestamp column to df_translate"""
    df_trans_time = df_translate.copy()

    # Assign an ID to each word in df_text['text'] and create a new DataFrame
    words = df_text['text'].str.split(expand=True).stack().reset_index(level=1, drop=True).reset_index()
    words.columns = ['id', 'word']
    words['id'] = words['id'].astype(int)

    # Process timestamps â°
    try:
        time_stamp_list = get_sentence_timestamps(df_text, df_translate)
    except Exception as e:
        console.print(f"[bold red]Critical Error in timestamp alignment: {str(e)}[/bold red]")
        # Fallback: Generate linear timestamps to prevent crash
        time_stamp_list = []
        curr = 0.0
        for _ in range(len(df_translate)):
            time_stamp_list.append((curr, curr+2.0))
            curr += 2.0
            
    df_trans_time['timestamp'] = time_stamp_list
    df_trans_time['duration'] = df_trans_time['timestamp'].apply(lambda x: x[1] - x[0])

    # Remove gaps ğŸ•³ï¸
    for i in range(len(df_trans_time)-1):
        if i+1 < len(df_trans_time):
            current_end = df_trans_time.loc[i, 'timestamp'][1]
            next_start = df_trans_time.loc[i+1, 'timestamp'][0]
            delta_time = next_start - current_end
            if 0 < delta_time < 1:
                df_trans_time.at[i, 'timestamp'] = (df_trans_time.loc[i, 'timestamp'][0], next_start)

    # Convert start and end timestamps to SRT format
    df_trans_time['timestamp'] = df_trans_time['timestamp'].apply(lambda x: convert_to_srt_format(x[0], x[1]))

    # Polish subtitles: replace punctuation in Translation if for_display
    if for_display:
        df_trans_time['Translation'] = df_trans_time['Translation'].apply(lambda x: re.sub(r'[ï¼Œã€‚]', ' ', str(x)).strip())

    # Output subtitles ğŸ“œ
    def generate_subtitle_string(df, columns):
        return ''.join([f"{i+1}\n{row['timestamp']}\n{str(row[columns[0]]).strip()}\n{str(row[columns[1]]).strip() if len(columns) > 1 else ''}\n\n" for i, row in df.iterrows()]).strip()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        for filename, columns in subtitle_output_configs:
            subtitle_str = generate_subtitle_string(df_trans_time, columns)
            with open(os.path.join(output_dir, filename), 'w', encoding='utf-8') as f:
                f.write(subtitle_str)
    
    return df_trans_time

# âœ¨ Beautify the translation
def clean_translation(x):
    if pd.isna(x):
        return ''
    cleaned = str(x).strip('ã€‚').strip('ï¼Œ')
    return autocorrect.format(cleaned)

def align_timestamp_main():
    df_text = pd.read_excel(_2_CLEANED_CHUNKS)
    df_text['text'] = df_text['text'].str.strip('"').str.strip()
    df_translate = pd.read_excel(_5_SPLIT_SUB)
    df_translate['Translation'] = df_translate['Translation'].apply(clean_translation)
    
    align_timestamp(df_text, df_translate, SUBTITLE_OUTPUT_CONFIGS, _OUTPUT_DIR)
    console.print(Panel("[bold green]ğŸ‰ğŸ“ Subtitles generation completed! Please check in the `output` folder ğŸ‘€[/bold green]"))

    # for audio
    df_translate_for_audio = pd.read_excel(_5_REMERGED) # use remerged file to avoid unmatched lines when dubbing
    df_translate_for_audio['Translation'] = df_translate_for_audio['Translation'].apply(clean_translation)
    
    align_timestamp(df_text, df_translate_for_audio, AUDIO_SUBTITLE_OUTPUT_CONFIGS, _AUDIO_DIR)
    console.print(Panel(f"[bold green]ğŸ‰ğŸ“ Audio subtitles generation completed! Please check in the `{_AUDIO_DIR}` folder ğŸ‘€[/bold green]"))
    

if __name__ == '__main__':
    align_timestamp_main()