import pandas as pd
import concurrent.futures
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

# 1. ÂØºÂÖ•Ê†∏ÂøÉÁøªËØëÂºïÊìé
from core.translate_lines import translate_batch_lines
# 2. ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∏∏Èáè
from core.utils.models import _3_2_SPLIT_BY_MEANING, _4_2_TRANSLATION, _2_CLEANED_CHUNKS
# 3. ÂØºÂÖ•Â∑•ÂÖ∑ÂáΩÊï∞
from core.utils import load_key, check_file_exists
from core._8_1_audio_task import check_len_then_trim
from core._6_gen_sub import align_timestamp

# ==============================================================================
# ÂÖ≥ÈîÆ‰øÆÂ§çÔºöÂØºÂÖ•ÈÖçÁΩÆÊñá‰ª∂ (Ë∑ØÂæÑÂ∏∏Èáè)
# ==============================================================================
try:
    from core.config import *
except ImportError:
    pass

console = Console()

# ==============================================================================
# 1. ÂàáÂàÜÈÄªËæë
# ==============================================================================
def split_chunks_by_chars(chunk_size, max_i): 
    """Ê†πÊçÆÂ≠óÁ¨¶Êï∞ÈôêÂà∂Â∞ÜÊñáÊú¨ÂàáÂàÜ‰∏∫ chunks"""
    with open(_3_2_SPLIT_BY_MEANING, "r", encoding="utf-8") as file:
        sentences = file.read().strip().split('\n')

    chunks = []
    chunk = ''
    sentence_count = 0
    for sentence in sentences:
        if len(chunk) + len(sentence + '\n') > chunk_size or sentence_count == max_i:
            if chunk:
                chunks.append(chunk.strip())
            chunk = sentence + '\n'
            sentence_count = 1
        else:
            chunk += sentence + '\n'
            sentence_count += 1
            
    if chunk:
        chunks.append(chunk.strip())
    return chunks

# ==============================================================================
# 2. Context Helper (‰∏ä‰∏ãÊñáËé∑Âèñ)
# ==============================================================================
def get_context(chunks, index, offset, lines_count):
    target_idx = index + offset
    if 0 <= target_idx < len(chunks):
        chunk_lines = chunks[target_idx].strip().split('\n')
        if offset < 0: return chunk_lines[-lines_count:] # ‰∏äÊñá
        else: return chunk_lines[:lines_count]           # ‰∏ãÊñá
    return []

# ==============================================================================
# 3. ‰ªªÂä°ÂåÖË£ÖÂô®
# ==============================================================================
def process_chunk(chunk, chunks, i):
    lines = chunk.strip().split('\n')
    # Ëé∑Âèñ‰∏ä‰∏ãÊñáÔºöÂâç‰∏ÄÂùóÁöÑÊúÄÂêé3Ë°åÔºåÂêé‰∏ÄÂùóÁöÑÂâç2Ë°å
    context_before = get_context(chunks, i, -1, 3)
    context_after = get_context(chunks, i, 1, 2)
    
    # Ë∞ÉÁî®Ê†∏ÂøÉÂºïÊìé
    trans_lines = translate_batch_lines(lines, context_before, context_after, chunk_index=i)
    
    return i, lines, trans_lines

# ==============================================================================
# 4. ‰∏ªÊµÅÁ®ã
# ==============================================================================
@check_file_exists(_4_2_TRANSLATION)
def translate_all():
    console.print("[bold green]üöÄ Start Batch Translation (Version C Engine)...[/bold green]")
    
    # 1. ÂàáÂàÜ‰ªªÂä°
    chunks = split_chunks_by_chars(chunk_size=600, max_i=10)
    
    # 2. Âπ∂ÂèëÊâßË°å
    results = []
    with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
        task = progress.add_task("[cyan]Translating...", total=len(chunks))
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=load_key("max_workers")) as executor:
            futures = [executor.submit(process_chunk, chunk, chunks, i) for i, chunk in enumerate(chunks)]
            
            for future in concurrent.futures.as_completed(futures):
                results.append(future.result())
                progress.update(task, advance=1)

    # 3. ÁªìÊûúÈáçÁªÑ
    results.sort(key=lambda x: x[0])
    
    all_src = []
    all_trans = []
    for _, src, trans in results:
        all_src.extend(src)
        all_trans.extend(trans)
        
    # 4. Êï∞ÊçÆ‰øùÂ≠ò (Excel & SRT)
    # ËØªÂèñÂéüÂßã Whisper ÂàáÁâáÁî®‰∫éÊó∂Èó¥ËΩ¥ÂØπÈΩê
    df_text = pd.read_excel(_2_CLEANED_CHUNKS)
    df_text['text'] = df_text['text'].str.strip('"').str.strip()
    
    # --- ÂÖ≥ÈîÆ‰øÆÂ§çÂºÄÂßã ---
    # ‰∏çË¶ÅÂº∫Ë°åÂØπÈΩê df_text ÁöÑÈïøÂ∫¶ÔºÅÂõ†‰∏∫Êàë‰ª¨ÂÅöËøáÂè•Â≠êÂàÜÂâ≤ÔºåË°åÊï∞ÂèòÂ§öÊòØÊ≠£Â∏∏ÁöÑ„ÄÇ
    # Âè™ÈúÄÁ°Æ‰øù Source Âíå Translation ‰∏Ä‰∏ÄÂØπÂ∫îÂç≥ÂèØ„ÄÇ
    
    if len(all_src) != len(all_trans):
        console.print(f"[bold red]‚ùå Critical Error: Source lines ({len(all_src)}) != Translation lines ({len(all_trans)})[/bold red]")
        # ÂÖúÂ∫ïÔºöÊà™Êñ≠Âà∞ÊúÄÁü≠ÈïøÂ∫¶ÔºåÈò≤Ê≠¢‰øùÂ≠òÂ§±Ë¥•
        min_len = min(len(all_src), len(all_trans))
        all_src = all_src[:min_len]
        all_trans = all_trans[:min_len]

    df_translate = pd.DataFrame({'Source': all_src, 'Translation': all_trans})
    # --- ÂÖ≥ÈîÆ‰øÆÂ§çÁªìÊùü ---
    
    # ÁîüÊàêÂ∏¶Êó∂Èó¥ËΩ¥ÁöÑ Excel
    # align_timestamp ‰ºöÈÄöËøáÊñáÊú¨Ê®°Á≥äÂåπÈÖçÔºåÂ∞Ü df_translate(Êó†Êó∂Èó¥) Êò†Â∞ÑÂà∞ df_text(ÊúâÊó∂Èó¥) ‰∏ä
    subtitle_configs = [('trans_subs_for_audio.srt', ['Translation'])]
    df_time = align_timestamp(df_text, df_translate, subtitle_configs, output_dir=None, for_display=False)
    
    # ÈïøÂ∫¶‰øÆÂâ™ (Trim)
    min_dur = load_key("min_trim_duration")
    df_time['Translation'] = df_time.apply(
        lambda x: check_len_then_trim(x['Translation'], x['duration']) if x['duration'] > min_dur else x['Translation'], 
        axis=1
    )
    
    console.print(df_time)
    df_time.to_excel(_4_2_TRANSLATION, index=False)
    console.print("[bold green]‚úÖ Translation Pipeline Completed![/bold green]")

if __name__ == '__main__':
    translate_all()