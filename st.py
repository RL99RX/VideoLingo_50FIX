import sys
import os
import types

# --- 5060Ti å…¼å®¹æ€§è¡¥ä¸ (ç»ˆæåŠ å¼ºç‰ˆ v4.0) ---
# å¿…é¡»åœ¨æ‰€æœ‰å…¶ä»– import ä¹‹å‰æ‰§è¡Œï¼
print("ğŸ”¥ åº”ç”¨ RTX 5060Ti å…¼å®¹æ€§è¡¥ä¸ (PyTorch/Torchaudio)...")

# 1. æŠ¢å…ˆå¯¼å…¥å¹¶ä¿®è¡¥ torch.load
import torch
_original_load = torch.load
def patched_load(*args, **kwargs):
    # å¼ºåˆ¶å…è®¸ weights_only=Falseï¼Œè§£å†³æ–°ç‰ˆ PyTorch åŠ è½½æ—§æ¨¡å‹æŠ¥é”™
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return _original_load(*args, **kwargs)
torch.load = patched_load

# 2. æŠ¢å…ˆå¯¼å…¥å¹¶ä¿®è¡¥ torchaudio
import torchaudio

# è¡¥ä¸ 2.1: ä¼ªé€ è¢«åˆ é™¤çš„ torchaudio.backend æ¨¡å—
# å¾ˆå¤šæ—§åº“ (å¦‚ pyannote) ä¼šå°è¯• import torchaudio.backend.common
if "torchaudio.backend" not in sys.modules:
    mock_backend = types.ModuleType("torchaudio.backend")
    mock_common = types.ModuleType("torchaudio.backend.common")
    
    class MockAudioMetaData:
        def __init__(self, sample_rate, num_frames, num_channels, bits_per_sample, encoding):
            self.sample_rate = sample_rate
            self.num_frames = num_frames
            self.num_channels = num_channels
            self.bits_per_sample = bits_per_sample
            self.encoding = encoding
            
    mock_common.AudioMetaData = MockAudioMetaData
    mock_backend.common = mock_common
    
    # æ³¨å…¥ç³»ç»Ÿæ¨¡å—åˆ—è¡¨ï¼Œéª—è¿‡åç»­çš„ import
    sys.modules["torchaudio.backend"] = mock_backend
    sys.modules["torchaudio.backend.common"] = mock_common

# è¡¥ä¸ 2.2: ä¼ªé€ è¢«åˆ é™¤çš„è€å‡½æ•°
# åªè¦åº“é‡Œæ²¡æœ‰è¿™äº›å‡½æ•°ï¼Œå°±åŸåœ°é€ ä¸€ä¸ªå‡çš„
if not hasattr(torchaudio, "set_audio_backend"): 
    torchaudio.set_audio_backend = lambda backend: None
if not hasattr(torchaudio, "get_audio_backend"): 
    torchaudio.get_audio_backend = lambda: "soundfile"
if not hasattr(torchaudio, "list_audio_backends"): 
    torchaudio.list_audio_backends = lambda: ["soundfile"]

print("âœ… å…¼å®¹æ€§è¡¥ä¸åº”ç”¨å®Œæˆã€‚")
# --- è¡¥ä¸ç»“æŸ ---

# æ­£å¸¸çš„ import å¼€å§‹
import streamlit as st
from core.st_utils.imports_and_utils import *
from core import *

# SET PATH
current_dir = os.path.dirname(os.path.abspath(__file__))
os.environ['PATH'] += os.pathsep + current_dir
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

st.set_page_config(page_title="VideoLingo", page_icon="docs/logo.svg")

SUB_VIDEO = "output/output_sub.mp4"
DUB_VIDEO = "output/output_dub.mp4"

# ... (ä¸‹é¢çš„ä»£ç ä¿æŒä¸å˜ï¼Œè¿™é‡Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…) ...
# ... è¯·æŠŠä½ åŸæ–‡ä»¶ä¸­ä» def text_processing_section(): å¼€å§‹çš„å†…å®¹å®Œæ•´ä¿ç•™ ...

def text_processing_section():
    st.header(t("b. Translate and Generate Subtitles"))
    with st.container(border=True):
        st.markdown(f"""
        <p style='font-size: 20px;'>
        {t("This stage includes the following steps:")}
        <p style='font-size: 20px;'>
            1. {t("WhisperX word-level transcription")}<br>
            2. {t("Sentence segmentation using NLP and LLM")}<br>
            3. {t("Summarization and multi-step translation")}<br>
            4. {t("Cutting and aligning long subtitles")}<br>
            5. {t("Generating timeline and subtitles")}<br>
            6. {t("Merging subtitles into the video")}
        """, unsafe_allow_html=True)

        if not os.path.exists(SUB_VIDEO):
            if st.button(t("Start Processing Subtitles"), key="text_processing_button"):
                process_text()
                st.rerun()
        else:
            if load_key("burn_subtitles"):
                st.video(SUB_VIDEO)
            download_subtitle_zip_button(text=t("Download All Srt Files"))
            
            if st.button(t("Archive to 'history'"), key="cleanup_in_text_processing"):
                cleanup()
                st.rerun()
            return True

def process_text():
    with st.spinner(t("Using Whisper for transcription...")):
        _2_asr.transcribe()
    with st.spinner(t("Splitting long sentences...")):  
        _3_1_split_nlp.split_by_spacy()
        _3_2_split_meaning.split_sentences_by_meaning()
    with st.spinner(t("Summarizing and translating...")):
        _4_1_summarize.get_summary()
        if load_key("pause_before_translate"):
            input(t("âš ï¸ PAUSE_BEFORE_TRANSLATE. Go to `output/log/terminology.json` to edit terminology. Then press ENTER to continue..."))
        _4_2_translate.translate_all()
    with st.spinner(t("Processing and aligning subtitles...")): 
        _5_split_sub.split_for_sub_main()
        _6_gen_sub.align_timestamp_main()
    with st.spinner(t("Merging subtitles to video...")):
        _7_sub_into_vid.merge_subtitles_to_video()
    
    st.success(t("Subtitle processing complete! ğŸ‰"))
    st.balloons()

def audio_processing_section():
    st.header(t("c. Dubbing"))
    with st.container(border=True):
        st.markdown(f"""
        <p style='font-size: 20px;'>
        {t("This stage includes the following steps:")}
        <p style='font-size: 20px;'>
            1. {t("Generate audio tasks and chunks")}<br>
            2. {t("Extract reference audio")}<br>
            3. {t("Generate and merge audio files")}<br>
            4. {t("Merge final audio into video")}
        """, unsafe_allow_html=True)
        if not os.path.exists(DUB_VIDEO):
            if st.button(t("Start Audio Processing"), key="audio_processing_button"):
                process_audio()
                st.rerun()
        else:
            st.success(t("Audio processing is complete! You can check the audio files in the `output` folder."))
            if load_key("burn_subtitles"):
                st.video(DUB_VIDEO) 
            if st.button(t("Delete dubbing files"), key="delete_dubbing_files"):
                delete_dubbing_files()
                st.rerun()
            if st.button(t("Archive to 'history'"), key="cleanup_in_audio_processing"):
                cleanup()
                st.rerun()

def process_audio():
    with st.spinner(t("Generate audio tasks")): 
        _8_1_audio_task.gen_audio_task_main()
        _8_2_dub_chunks.gen_dub_chunks()
    with st.spinner(t("Extract refer audio")):
        _9_refer_audio.extract_refer_audio_main()
    with st.spinner(t("Generate all audio")):
        _10_gen_audio.gen_audio()
    with st.spinner(t("Merge full audio")):
        _11_merge_audio.merge_full_audio()
    with st.spinner(t("Merge dubbing to the video")):
        _12_dub_to_vid.merge_video_audio()
    
    st.success(t("Audio processing complete! ğŸ‡"))
    st.balloons()

def main():
    logo_col, _ = st.columns([1,1])
    with logo_col:
        st.image("docs/logo.png", use_column_width=True)
    st.markdown(button_style, unsafe_allow_html=True)
    welcome_text = t("Hello, welcome to VideoLingo. If you encounter any issues, feel free to get instant answers with our Free QA Agent <a href=\"https://share.fastgpt.in/chat/share?shareId=066w11n3r9aq6879r4z0v9rh\" target=\"_blank\">here</a>! You can also try out our SaaS website at <a href=\"https://videolingo.io\" target=\"_blank\">videolingo.io</a> for free!")
    st.markdown(f"<p style='font-size: 20px; color: #808080;'>{welcome_text}</p>", unsafe_allow_html=True)
    # add settings
    with st.sidebar:
        page_setting()
        st.markdown(give_star_button, unsafe_allow_html=True)
        
        # ğŸŸ¢ å¢åŠ ï¼šæ‰‹åŠ¨ä¸Šä¼ æ–‡ä»¶ä¿å­˜é€»è¾‘ (é˜²æ­¢ä¸Šä¼ åæ²¡ååº”)
        # è¿™éƒ¨åˆ†ä»£ç åœ¨ä½ æä¾›çš„åŸæ–‡ä»¶é‡Œæ²¡æœ‰ï¼Œå»ºè®®åŠ ä¸Šä»¥é˜²ä¸‡ä¸€
        # video_file = st.file_uploader("ğŸ“ ä¸Šä¼ æœ¬åœ°è§†é¢‘", type=['mp4', 'mov', 'avi', 'mkv', 'webm'])
        # if video_file is not None:
        #     # ... ä¿å­˜é€»è¾‘ ...
        #     pass

    download_video_section()
    text_processing_section()
    audio_processing_section()

if __name__ == "__main__":
    main()